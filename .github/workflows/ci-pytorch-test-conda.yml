name: Test PyTorch with Conda

# see: https://help.github.com/en/actions/reference/events-that-trigger-workflows
on:  # Trigger the workflow on push or pull request, but only for the master branch
  push:
    branches: [master, "release/*"]
  pull_request:
    branches: [master, "release/*"]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-${{ github.head_ref }}
  cancel-in-progress: ${{ ! (github.ref == 'refs/heads/master' || startsWith(github.ref, 'refs/heads/release/')) }}

defaults:
  run:
    shell: bash -l {0}

jobs:
  conda:
    runs-on: ubuntu-20.04
    container: pytorchlightning/pytorch_lightning:base-conda-py${{ matrix.python-version }}-torch${{ matrix.pytorch-version }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - {python-version: "3.8", pytorch-version: "1.9"}
          - {python-version: "3.8", pytorch-version: "1.10"}
          - {python-version: "3.9", pytorch-version: "1.11"}
          - {python-version: "3.9", pytorch-version: "1.12"}
    timeout-minutes: 30

    steps:
    - name: Workaround for https://github.com/actions/checkout/issues/760
      run: git config --global --add safe.directory /__w/lightning/lightning

    - uses: actions/checkout@v2

    - name: Get changed files
      id: changed-files
      uses: tj-actions/changed-files@v24

    - name: Decide if the test should be skipped
      id: skip
      shell: bash -l {0}
      run: |
        FILTER='src/pytorch_lightning|requirements/pytorch|tests/tests_pytorch|examples/pl_*|.github/workflows/ci-pytorch-test-conda.yml'
        echo "${{ steps.changed-files.outputs.all_changed_files }}" | tr " " "\n" > changed_files.txt
        MATCHES=$(cat changed_files.txt | grep -E $FILTER)
        echo $MATCHES
        if [ -z "$MATCHES" ]; then
            echo "Skip"
            echo "::set-output name=continue::0"
        else
            echo "Continue"
            echo "::set-output name=continue::1"
        fi

    - name: Update base dependencies
      if: ${{ (steps.skip.outputs.continue == '1') }}
      env:
        PACKAGE_NAME: pytorch
        FREEZE_REQUIREMENTS: 1
      run: |
        conda info
        conda list
        pip install -e .[test]

    - name: Freeze PIL (hotfix)
      # import of PILLOW_VERSION which they recently removed in v9.0 in favor of __version__
      run: pip install "Pillow<9.0"  # It messes with torchvision

    - name: DocTests
      if: ${{ (steps.skip.outputs.continue == '1') }}
      working-directory: ./src
      run: pytest pytorch_lightning --cov=pytorch_lightning

    - name: Update all dependencies
      if: ${{ (steps.skip.outputs.continue == '1') }}
      env:
        HOROVOD_BUILD_ARCH_FLAGS: "-mfma"
        HOROVOD_WITHOUT_MXNET: 1
        HOROVOD_WITHOUT_TENSORFLOW: 1
      run: |
        set -e
        pip list
        # adjust versions according installed Torch version
        python ./requirements/pytorch/adjust-versions.py requirements/pytorch/extra.txt
        python ./requirements/pytorch/adjust-versions.py requirements/pytorch/examples.txt
        pip install -r requirements/pytorch/devel.txt --find-links https://download.pytorch.org/whl/torch_stable.html
        pip install -r requirements/pytorch/strategies.txt
        # set a per-test timeout of 2.5 minutes to fail sooner; this aids with hanging tests
        pip install pytest-timeout
        pip list
        # sanity check
        python requirements/pytorch/check-avail-extras.py

    - name: Pull legacy checkpoints
      if: ${{ (steps.skip.outputs.continue == '1') }}
      run: bash .actions/pull_legacy_checkpoints.sh

    - name: Testing PyTorch
      if: ${{ (steps.skip.outputs.continue == '1') }}
      working-directory: tests/tests_pytorch
      run: coverage run --source pytorch_lightning -m pytest -v --timeout 150 --durations=50 --junitxml=results-${{ runner.os }}-torch${{ matrix.pytorch-version }}.xml

    - name: Upload pytest results
      uses: actions/upload-artifact@v3
      with:
        name: unittest-results-${{ runner.os }}-torch${{ matrix.pytorch-version }}
        path: tests/tests_pytorch/results-${{ runner.os }}-torch${{ matrix.pytorch-version }}.xml
      if: failure()

    - name: Statistics
      if: ${{ success() && (steps.skip.outputs.continue == '1') }}
      working-directory: tests/tests_pytorch
      run: |
        coverage report
        coverage xml

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: ${{ success() && (steps.skip.outputs.continue == '1') }}
      # see: https://github.com/actions/toolkit/issues/399
      continue-on-error: true
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        file: tests/tests_pytorch/coverage.xml
        flags: cpu,pytest,torch${{ matrix.pytorch-version }}
        name: CPU-coverage
        fail_ci_if_error: false
