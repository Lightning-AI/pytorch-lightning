# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python

trigger:
  tags:
    include: ["*"]
  branches:
    include:
      - "master"
      - "release/*"
      - "refs/tags/*"

pr:
  branches:
    include:
      - "master"
      - "release/*"
  paths:
    include:
      - ".actions/*"
      - ".azure/gpu-tests-fabric.yml"
      - "examples/fabric/**"
      - "examples/run_fabric_examples.sh"
      - "tests/run_standalone_*.sh"
      - "requirements/fabric/**"
      - "src/lightning/__init__.py"
      - "src/lightning/__setup__.py"
      - "src/lightning/__version__.py"
      - "src/lightning/fabric/**"
      - "src/lightning_fabric/*"
      - "tests/tests_fabric/**"
      - "pyproject.toml" # includes pytest config
    exclude:
      - "requirements/*/docs.txt"
      - "*.md"
      - "**/*.md"

jobs:
  - job: testing
    # how long to run the job before automatically cancelling
    timeoutInMinutes: "20"
    # how much time to give 'run always even if cancelled tasks' before stopping them
    cancelTimeoutInMinutes: "2"
    pool: lit-rtx-3090
    variables:
      DEVICES: $( python -c 'print("$(Agent.Name)".split("_")[-1])' )
      FREEZE_REQUIREMENTS: "1"
      PIP_CACHE_DIR: "/var/tmp/pip"
      RUN_ONLY_CUDA_TESTS: "1"
    container:
      image: $(image)
      # default shm size is 64m. Increase it to avoid:
      # 'Error while creating shared memory: unhandled system error, NCCL version 2.7.8'
      options: "--gpus=all --shm-size=2gb  -v /var/tmp:/var/tmp"
    strategy:
      matrix:
        "Fabric | oldest":
          image: "pytorchlightning/pytorch_lightning:base-cuda12.1.1-py3.10-torch2.1"
          PACKAGE_NAME: "fabric"
        "Fabric | latest":
          image: "pytorchlightning/pytorch_lightning:base-cuda12.6.3-py3.12-torch2.8"
          PACKAGE_NAME: "fabric"
        #"Fabric | future":
        #  image: "pytorchlightning/pytorch_lightning:base-cuda12.6.3-py3.12-torch2.7"
        #  PACKAGE_NAME: "fabric"
        "Lightning | latest":
          image: "pytorchlightning/pytorch_lightning:base-cuda12.6.3-py3.12-torch2.8"
          PACKAGE_NAME: "lightning"
    workspace:
      clean: all
    steps:
      - bash: |
          echo "##vso[task.setvariable variable=CUDA_VISIBLE_DEVICES]$(DEVICES)"
          cuda_ver=$(python -c "import torch ; print(''.join(map(str, torch.version.cuda.split('.')[:2])))")
          echo "##vso[task.setvariable variable=CUDA_VERSION_MM]$cuda_ver"
          echo "##vso[task.setvariable variable=TORCH_URL]https://download.pytorch.org/whl/cu${cuda_ver}/torch_stable.html"
          scope=$(python -c 'n = "${PACKAGE_NAME}" ; print(dict(fabric="lightning_fabric").get(n, n))')
          echo "##vso[task.setvariable variable=COVERAGE_SOURCE]$scope"
        displayName: "set env. vars"
      - bash: |
          echo "##vso[task.setvariable variable=TORCH_URL]https://download.pytorch.org/whl/test/cu${CUDA_VERSION_MM}"
        condition: endsWith(variables['Agent.JobName'], 'future')
        displayName: "extend env. vars 4 future"

      - bash: |
          set -ex
          echo $(DEVICES)
          echo $CUDA_VISIBLE_DEVICES
          echo $CUDA_VERSION_MM
          echo $TORCH_URL
          echo $COVERAGE_SOURCE
          whereis nvidia
          nvidia-smi
          which python && which pip
          python --version
          pip --version
          pip list
          # todo: rather use devel base image
          apt-get update -qq --fix-missing
          apt-get install -y cuda-toolkit
          nvcc --version
        displayName: "Image info & NVIDIA"

      - bash: |
          set -ex
          pip install "cython<3.0" wheel  # for compatibility
          pip install -U "lightning-utilities[cli]"
          cd requirements/fabric
          # replace range by pin minimal requirements
          python -m lightning_utilities.cli requirements set-oldest --req_files "['base.txt', 'strategies.txt']"
          # drop deepspeed since it is not supported by our minimal Torch requirements
          python -m lightning_utilities.cli requirements prune-pkgs --packages deepspeed --req_files strategies.txt
          # uninstall deepspeed since some older docker images have it pre-installed
          pip uninstall -y deepspeed
        condition: contains(variables['Agent.JobName'], 'oldest')
        displayName: "setting oldest dependencies"

      - bash: |
          PYTORCH_VERSION=$(python -c "import torch; print(torch.__version__.split('+')[0])")
          pip install -q wget packaging
          python -m wget https://raw.githubusercontent.com/Lightning-AI/utilities/main/scripts/adjust-torch-versions.py
          for fpath in `ls requirements/**/*.txt`; do \
            python ./adjust-torch-versions.py $fpath ${PYTORCH_VERSION}; \
          done
        displayName: "Adjust dependencies"

      - bash: |
          pip install -U -q -r .actions/requirements.txt
          python .actions/assistant.py copy_replace_imports --source_dir="./tests/tests_fabric" \
            --source_import="lightning.fabric" \
            --target_import="lightning_fabric"
          python .actions/assistant.py copy_replace_imports --source_dir="./examples/fabric" \
            --source_import="lightning.fabric" \
            --target_import="lightning_fabric"
        # without succeeded this could run even if the job has already failed
        condition: and(succeeded(), eq(variables['PACKAGE_NAME'], 'fabric'))
        displayName: "Adjust tests & examples"

      - bash: |
          set -e
          extra=$(python -c "print({'lightning': 'fabric-'}.get('${PACKAGE_NAME}', ''))")
          pip install -e ".[${extra}dev]" -U --upgrade-strategy=eager --extra-index-url="${TORCH_URL}"
        displayName: "Install package & dependencies"

      - bash: |
          set -e
          python requirements/collect_env_details.py
          python -c "import torch ; mgpu = torch.cuda.device_count() ; assert mgpu == 2, f'GPU: {mgpu}'"
          python requirements/pytorch/check-avail-extras.py
          python -c "import bitsandbytes"
        displayName: "Env details"

      - bash: python -m pytest lightning_fabric
        workingDirectory: src
        # without succeeded this could run even if the job has already failed
        condition: and(succeeded(), eq(variables['PACKAGE_NAME'], 'fabric'))
        displayName: "Testing: Fabric doctests"

      - bash: python -m coverage run --source ${COVERAGE_SOURCE} -m pytest tests_fabric/ -v --durations=50
        workingDirectory: tests/
        displayName: "Testing: fabric standard"
        timeoutInMinutes: "15"

      - bash: |
          wget https://raw.githubusercontent.com/Lightning-AI/utilities/main/scripts/run_standalone_tests.sh
          bash ./run_standalone_tests.sh "tests_fabric"
        workingDirectory: tests/
        env:
          PL_RUN_STANDALONE_TESTS: "1"
        displayName: "Testing: fabric standalone"
        timeoutInMinutes: "15"

      - bash: |
          python -m coverage report
          python -m coverage xml
          python -m coverage html

          # https://docs.codecov.com/docs/codecov-uploader
          curl -Os https://uploader.codecov.io/latest/linux/codecov
          chmod +x codecov
          ./codecov --token=$(CODECOV_TOKEN) --commit=$(Build.SourceVersion) \
            --flags=gpu,pytest,${COVERAGE_SOURCE} --name="GPU-coverage" --env=linux,azure
          ls -l
        workingDirectory: tests/
        displayName: "Statistics"

      - script: |
          set -e
          bash run_fabric_examples.sh --accelerator=cuda --devices=1
          bash run_fabric_examples.sh --accelerator=cuda --devices=2 --strategy ddp
        workingDirectory: examples/
        displayName: "Testing: fabric examples"
