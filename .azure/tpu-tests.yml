trigger:
  tags:
    include:
      - '*'
  branches:
    include:
      - "master"
      - "release/*"
      - "refs/tags/*"

pr:
  - "master"
  - "release/*"

variables:
  - name: XLA
    value: "1.12"
  - name: Python
    value: "1.1"
  - name: max_checks
    value: 10000
  - name: check_sleep
    value: 5
  # variables are automatically exported as environment variables so this will override pip's default cache dir
  - name: pip_cache_dir
    value: $(Pipeline.Workspace)/.pip

# Workflow Steps:
#  1. Checkout
#  2. Install GO
#  3. Checkout ml-testing-accelerators
#  4. GCP GKE install
#  5. Update Kubeconfig with credintials
#  6. Install jsonnet
#  7. Update jsonnet
#  8. Deploy the job on the kubernetes cluster
#  9. Statistics
#  10. Upload coverage results
#  11. Upload coverage to Codecov


jobs:
  - job: testing
    pool:
      vmImage: 'ubuntu-latest'
    timeoutInMinutes: "50"
    cancelTimeoutInMinutes: "2"
    workspace:
      clean: all
    steps:
    - task: UsePythonVersion@0
      inputs:
        versi`onSpec: '3.7'

    - bash: |
        git clone https://github.com/GoogleCloudPlatform/ml-testing-accelerators.git
        cd ml-testing-accelerators
        git fetch origin 5e88ac24f631c27045e62f0e8d5dfcf34e425e25:stable
        git checkout stable
      displayName: 'Checkout ml-testing-accelerators'

    # TODO: gcp-gke/install

    # TODO: gcp-gke/update-kubeconfig-with-credentials:
    #          cluster: $GKE_CLUSTER
    #          perform-login: true

    - bash: go install github.com/google/go-jsonnet/cmd/jsonnet@latest
      displayName: 'Install jsonnet'

    - bash: |
        export PR_NUMBER=$(git ls-remote origin "pull/*/head" | grep -F -f <(git rev-parse HEAD) | awk -F'/' '{print $3}')
        export SHA=$(git rev-parse --short HEAD)
        python -c "fname = 'dockers/tpu-tests/tpu_test_cases.jsonnet' ; data = open(fname).read().replace('{PYTORCH_VERSION}', ${{ variables.XLA }})
        data = data.replace('{PYTHON_VERSION}', ${{ variables.Python }}).replace('{PR_NUMBER}', '$PR_NUMBER').replace('{SHA}', '$SHA') ; open(fname, 'w').write(data)"
        cat dockers/tpu-tests/tpu_test_cases.jsonnet
      displayName: 'Update jsonnet'

    - bash: |
        job_name=$(jsonnet -J ml-testing-accelerators/ dockers/tpu-tests/tpu_test_cases.jsonnet | kubectl create -f -) && \
        job_name=${job_name#job.batch/}
        job_name=${job_name% created}
        pod_name=$(kubectl get po -l controller-uid=`kubectl get job $job_name -o "jsonpath={.metadata.labels.controller-uid}"` | awk 'match($0,!/NAME/) {print $1}')
        echo "GKE pod name: $pod_name"
        echo "Waiting on kubernetes job: $job_name"
        i=0 && \
        # N checks spaced 30s apart = 900s total.
        status_code=2 && \
        # Check on the job periodically. Set the status code depending on what
        # happened to the job in Kubernetes. If we try MAX_CHECKS times and
        # still the job hasn't finished, give up and return the starting
        # non-zero status code.
        printf "Waiting for job to finish: " && \
        while [ $i -lt ${{ variables.max_checks }} ]; do ((i++)); if kubectl get jobs $job_name -o jsonpath='Failed:{.status.failed}' | grep "Failed:1"; then status_code=1 && break; elif kubectl get jobs $job_name -o jsonpath='Succeeded:{.status.succeeded}' | grep "Succeeded:1" ; then status_code=0 && break; else printf "."; fi; sleep ${{ variables.check_sleep }}; done && \
        echo "Done waiting. Job status code: $status_code" && \
        kubectl logs -f $pod_name --container=train > /tmp/full_output.txt
        if grep -q '<?xml version="1.0" ?>' /tmp/full_output.txt ; then csplit /tmp/full_output.txt '/<?xml version="1.0" ?>/'; else mv /tmp/full_output.txt xx00; fi && \
        # First portion is the test logs. Print these to Github Action stdout.
        cat xx00 && \
        echo "Done with log retrieval attempt." && \
        exit $status_code
      env:
        PATH: $PATH:$HOME/go/bin
      displayName: 'Deploy the job on the kubernetes cluster'

    - bash: mv ./xx01 coverage.xml
      displayName: 'Statistics'

    - bash: |
        python -m coverage report
        python -m codecov --token=$(CODECOV_TOKEN) --commit=$(Build.SourceVersion) --flags=tpu,pytest --name="TPU-coverage" --env=linux,azure
      displayName: 'Statistics'
